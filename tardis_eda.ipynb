{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import pandas to read, parse, store and do anything to our dataframe followed by numpy for matrices and math functions\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Pandas_logo.svg/1920px-Pandas_logo.svg.png\" width=\"512\" height=\"207\">\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/NumPy_logo_2020.svg/1920px-NumPy_logo_2020.svg.png\" width=\"512\" height=\"230\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by reading the \"dataset.csv\" file and make it a dataframe <br>\n",
    "The delimiter in the dataset is ';'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv(\"dataset.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all comment columns since they're not data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = csv.drop(\"Cancellation comments\", axis=1)\n",
    "csv = csv.drop(\"Departure delay comments\", axis=1)\n",
    "csv = csv.drop(\"Arrival delay comments\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = csv.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Date column\n",
    "The date format must be %Y-%m (A year and a month) <br>\n",
    "We replace all wrong delimiters by a '-' <br>\n",
    "We convert all the strings to datetimes under the wanted format <br>\n",
    "We exclude all data from before 2000 and after today <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv[\"Date\"] = csv[\"Date\"].astype(str).str.replace(r\"(\\d{4})\\w(\\d{2})\", r\"\\1-\\2\", regex=True)\n",
    "csv[\"Date\"] = pd.to_datetime(csv[\"Date\"], errors=\"coerce\", format=\"%Y-%m\")\n",
    "today = pd.to_datetime(\"today\").normalize()\n",
    "csv.loc[(csv.Date < \"2000-01\") | (csv.Date > today), \"Date\"] = pd.NaT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Service column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv[\"Service\"] = csv[\"Service\"].convert_dtypes(str)\n",
    "services = ~csv[\"Service\"].isin([\"National\", \"International\", \"national\", \"international\"])\n",
    "csv.loc[services, \"Service\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Departure station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv[\"Departure station\"] = csv[\"Departure station\"].convert_dtypes(str)\n",
    "numbers = csv[\"Departure station\"].str.contains(r\".*\\d.*\", na=False)\n",
    "csv.loc[numbers, \"Departure station\"] = np.nan\n",
    "lowercase = csv[\"Departure station\"].str.contains(r\"[a-z]\", na=False)\n",
    "csv.loc[lowercase, \"Departure station\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Arrival station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv[\"Arrival station\"] = csv[\"Arrival station\"].convert_dtypes(str)\n",
    "mask = csv[\"Arrival station\"].str.contains(r\".*\\d.*\", na=False)\n",
    "csv.loc[mask, \"Arrival station\"] = np.nan\n",
    "lowercase = csv[\"Arrival station\"].str.contains(r\"[a-z]\", na=False)\n",
    "csv.loc[lowercase, \"Arrival station\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Average journey time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Average journey time\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Average journey time\"] = np.nan\n",
    "csv[\"Average journey time\"] = csv[\"Average journey time\"].convert_dtypes(float)\n",
    "csv.loc[csv[\"Average journey time\"] < 0, \"Average journey time\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Number of scheduled trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Number of scheduled trains\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Number of scheduled trains\"] = np.nan\n",
    "csv.loc[csv[\"Number of scheduled trains\"] % 1 != 0, \"Number of scheduled trains\"] = np.nan\n",
    "csv[\"Number of scheduled trains\"] = csv[\"Number of scheduled trains\"].convert_dtypes(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Number of cancelled trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Number of cancelled trains\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Number of cancelled trains\"] = np.nan\n",
    "csv.loc[csv[\"Number of cancelled trains\"] % 1 != 0, \"Number of cancelled trains\"] = np.nan\n",
    "csv[\"Number of cancelled trains\"] = csv[\"Number of cancelled trains\"].convert_dtypes(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Number of trains delayed at departure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Number of trains delayed at departure\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Number of trains delayed at departure\"] = np.nan\n",
    "csv.loc[csv[\"Number of trains delayed at departure\"] % 1 != 0, \"Number of trains delayed at departure\"] = np.nan\n",
    "csv.loc[csv[\"Number of trains delayed at departure\"] > csv[\"Number of scheduled trains\"], \"Number of trains delayed at departure\"] = np.nan\n",
    "csv[\"Number of trains delayed at departure\"] = csv[\"Number of trains delayed at departure\"].convert_dtypes(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Average delay of late trains at departure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Average delay of late trains at departure\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Average delay of late trains at departure\"] = np.nan\n",
    "csv[\"Average delay of late trains at departure\"] = csv[\"Average delay of late trains at departure\"].convert_dtypes(float)\n",
    "csv.loc[csv[\"Average delay of late trains at departure\"] < 0, \"Average delay of late trains at departure\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Average delay of all trains at departure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Average delay of all trains at departure\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Average delay of all trains at departure\"] = np.nan\n",
    "csv[\"Average delay of all trains at departure\"] = csv[\"Average delay of all trains at departure\"].convert_dtypes(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Number of trains delayed at arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Number of trains delayed at arrival\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Number of trains delayed at arrival\"] = np.nan\n",
    "csv.loc[csv[\"Number of trains delayed at arrival\"] % 1 != 0, \"Number of trains delayed at arrival\"] = np.nan\n",
    "csv.loc[csv[\"Number of trains delayed at arrival\"] > csv[\"Number of scheduled trains\"], \"Number of trains delayed at arrival\"] = np.nan\n",
    "csv[\"Number of trains delayed at arrival\"] = csv[\"Number of trains delayed at arrival\"].convert_dtypes(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Average delay of late trains at arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Average delay of late trains at arrival\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Average delay of late trains at arrival\"] = np.nan\n",
    "csv[\"Average delay of late trains at arrival\"] = csv[\"Average delay of late trains at arrival\"].convert_dtypes(float)\n",
    "csv.loc[csv[\"Average delay of late trains at arrival\"] < 0, \"Average delay of late trains at arrival\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Average delay of all trains at arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Average delay of all trains at arrival\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Average delay of all trains at arrival\"] = np.nan\n",
    "csv[\"Average delay of all trains at arrival\"] = csv[\"Average delay of all trains at arrival\"].convert_dtypes(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Number of trains delayed > 15 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Number of trains delayed > 15min\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Number of trains delayed > 15min\"] = np.nan\n",
    "csv.loc[csv[\"Number of trains delayed > 15min\"] % 1 != 0, \"Number of trains delayed > 15min\"] = np.nan\n",
    "csv.loc[csv[\"Number of trains delayed > 15min\"] > csv[\"Number of trains delayed at departure\"] + csv[\"Number of trains delayed at arrival\"], \"Number of trains delayed > 15min\"] = np.nan\n",
    "csv[\"Number of trains delayed > 15min\"] = csv[\"Number of trains delayed > 15min\"].convert_dtypes(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Average delay of trains > 15min (if competing with flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Average delay of trains > 15min (if competing with flights)\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Average delay of trains > 15min (if competing with flights)\"] = np.nan\n",
    "csv[\"Average delay of trains > 15min (if competing with flights)\"] = csv[\"Average delay of trains > 15min (if competing with flights)\"].convert_dtypes(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Number of trains delayed > 30min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Number of trains delayed > 30min\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Number of trains delayed > 30min\"] = np.nan\n",
    "csv.loc[csv[\"Number of trains delayed > 30min\"] % 1 != 0, \"Number of trains delayed > 30min\"] = np.nan\n",
    "csv.loc[csv[\"Number of trains delayed > 30min\"] > csv[\"Number of trains delayed > 15min\"], \"Number of trains delayed > 30min\"] = np.nan\n",
    "csv[\"Number of trains delayed > 30min\"] = csv[\"Number of trains delayed > 30min\"].convert_dtypes(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Number of trains delayed > 60min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Number of trains delayed > 60min\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Number of trains delayed > 60min\"] = np.nan\n",
    "csv.loc[csv[\"Number of trains delayed > 60min\"] % 1 != 0, \"Number of trains delayed > 60min\"] = np.nan\n",
    "csv.loc[csv[\"Number of trains delayed > 60min\"] > csv[\"Number of trains delayed > 30min\"], \"Number of trains delayed > 60min\"] = np.nan\n",
    "csv[\"Number of trains delayed > 60min\"] = csv[\"Number of trains delayed > 60min\"].convert_dtypes(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Pct delay due to external causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Pct delay due to external causes\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Pct delay due to external causes\"] = np.nan\n",
    "csv[\"Pct delay due to external causes\"] = csv[\"Pct delay due to external causes\"].convert_dtypes(float)\n",
    "csv.loc[(csv[\"Pct delay due to external causes\"] > 100) | (csv[\"Pct delay due to external causes\"] < 0), \"Pct delay due to external causes\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Pct delay due to infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Pct delay due to infrastructure\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Pct delay due to infrastructure\"] = np.nan\n",
    "csv[\"Pct delay due to infrastructure\"] = csv[\"Pct delay due to infrastructure\"].convert_dtypes(float)\n",
    "csv.loc[(csv[\"Pct delay due to infrastructure\"] > 100) | (csv[\"Pct delay due to infrastructure\"] < 0), \"Pct delay due to infrastructure\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Pct delay due to traffic management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Pct delay due to traffic management\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Pct delay due to traffic management\"] = np.nan\n",
    "csv[\"Pct delay due to traffic management\"] = csv[\"Pct delay due to traffic management\"].convert_dtypes(float)\n",
    "csv.loc[(csv[\"Pct delay due to traffic management\"] > 100) | (csv[\"Pct delay due to traffic management\"] < 0), \"Pct delay due to traffic management\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Pct delay due to rolling stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Pct delay due to rolling stock\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Pct delay due to rolling stock\"] = np.nan\n",
    "csv[\"Pct delay due to rolling stock\"] = csv[\"Pct delay due to rolling stock\"].convert_dtypes(float)\n",
    "csv.loc[(csv[\"Pct delay due to rolling stock\"] > 100) | (csv[\"Pct delay due to rolling stock\"] < 0), \"Pct delay due to rolling stock\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Pct delay due to station management and equipment reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Pct delay due to station management and equipment reuse\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Pct delay due to station management and equipment reuse\"] = np.nan\n",
    "csv[\"Pct delay due to station management and equipment reuse\"] = csv[\"Pct delay due to station management and equipment reuse\"].convert_dtypes(float)\n",
    "csv.loc[(csv[\"Pct delay due to station management and equipment reuse\"] > 100) | (csv[\"Pct delay due to station management and equipment reuse\"] < 0), \"Pct delay due to station management and equipment reuse\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Pct delay due to passenger handling (crowding, disabled persons, connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Pct delay due to passenger handling (crowding, disabled persons, connections)\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Pct delay due to passenger handling (crowding, disabled persons, connections)\"] = np.nan\n",
    "csv[\"Pct delay due to passenger handling (crowding, disabled persons, connections)\"] = csv[\"Pct delay due to passenger handling (crowding, disabled persons, connections)\"].convert_dtypes(float)\n",
    "csv.loc[(csv[\"Pct delay due to passenger handling (crowding, disabled persons, connections)\"] > 100) | (csv[\"Pct delay due to passenger handling (crowding, disabled persons, connections)\"] < 0), \"Pct delay due to passenger handling (crowding, disabled persons, connections)\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final informations <br>\n",
    "After dropping all null lines, we get 941 perfectly correct lines <br>\n",
    "Compared to 10662 when not dropped <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv_dropped = csv.dropna()\n",
    "#csv_dropped.info()\n",
    "csv.info()\n",
    "csv = csv.sort_values([\"Date\", \"Service\", \"Departure station\", \"Arrival station\"])\n",
    "#csv.to_csv(\"parsed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
