{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import pandas to read, parse, store and do anything to our dataframe followed by numpy for matrices and math functions. Levenshtein is used to get the closest string, used for typos.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Pandas_logo.svg/1920px-Pandas_logo.svg.png\" width=\"512\" height=\"207\">\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/NumPy_logo_2020.svg/1920px-NumPy_logo_2020.svg.png\" width=\"512\" height=\"230\">\n",
    "<img src=\"https://ethw.org/w/images/8/83/Levenshtein.jpg\" width=\"216\" height=\"269\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Levenshtein as lev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by reading the \"dataset.csv\" file and make it a dataframe <br>\n",
    "The delimiter in the dataset is ';'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv(\"dataset.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all comment columns since they're not 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = csv.drop(\"Cancellation comments\", axis=1)\n",
    "csv = csv.drop(\"Departure delay comments\", axis=1)\n",
    "csv = csv.drop(\"Arrival delay comments\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = csv.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Date column\n",
    "The date format must be %Y-%m (A year and a month) <br>\n",
    "We replace all wrong delimiters by a '-' <br>\n",
    "We convert all the strings to datetimes under the wanted format <br>\n",
    "We exclude all data from before 2015 and after today <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv[\"Date\"] = csv[\"Date\"].astype(str).str.replace(r\"(\\d{4})\\w(\\d{2})\", r\"\\1-\\2\", regex=True)\n",
    "csv[\"Date\"] = pd.to_datetime(csv[\"Date\"], errors=\"coerce\", format=\"%Y-%m\")\n",
    "today = pd.to_datetime(\"today\").normalize()\n",
    "csv.loc[(csv.Date < \"2015-01\") | (csv.Date > today), \"Date\"] = pd.NaT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Service column\n",
    "We convert the column to strings <br>\n",
    "Using levenshtein's algorithm, we find the closest Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv[\"Service\"] = csv[\"Service\"].convert_dtypes(str)\n",
    "\n",
    "services = [\"NATIONAL\", \"INTERNATIONAL\"]\n",
    "\n",
    "max_val = 0\n",
    "max_service = \"\"\n",
    "\n",
    "for x in range(len(csv[\"Service\"])):\n",
    "    for service in services:\n",
    "        if (x in csv[\"Service\"]):\n",
    "            a = lev.ratio(str(csv[\"Service\"][x]).upper(), service)\n",
    "            if (a > max_val and a > 0.7):\n",
    "                max_val = a\n",
    "                max_service = service\n",
    "    max_val = 0\n",
    "    csv[\"Service\"][x] = max_service\n",
    "    max_service = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Departure station\n",
    "We convert the column to strings <br>\n",
    "We remove any station name that contains numbers <br>\n",
    "Using levenshtein's algorithm, we find the closest station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv[\"Departure station\"] = csv[\"Departure station\"].convert_dtypes(str)\n",
    "numbers = csv[\"Departure station\"].str.contains(r\".*\\d.*\", na=False)\n",
    "csv.loc[numbers, \"Departure station\"] = np.nan\n",
    "csv[\"Departure station\"] = csv[\"Departure station\"].str.upper()\n",
    "\n",
    "cities_list = ['AIX EN PROVENCE TGV',\n",
    "               'ANGERS SAINT LAUD',\n",
    "               'ANGOULEME',\n",
    "               'ANNECY',\n",
    "               'ARRAS',\n",
    "               'AVIGNON TGV',\n",
    "               'BARCELONA',\n",
    "               'BELLEGARDE (AIN)',\n",
    "               'BESANCON FRANCHE COMTE TGV',\n",
    "               'BORDEAUX ST JEAN',\n",
    "               'BREST',\n",
    "               'CHAMBERY CHALLES LES EAUX',\n",
    "               'DIJON VILLE',\n",
    "               'DOUAI', \n",
    "               'DUNKERQUE', \n",
    "               'FRANCFORT', \n",
    "               'GENEVE', \n",
    "               'GRENOBLE', \n",
    "               'ITALIE', \n",
    "               'LA ROCHELLE VILLE', \n",
    "               'LAUSANNE', \n",
    "               'LAVAL', \n",
    "               'LE CREUSOT MONTCEAU MONTCHANIN', \n",
    "               'LE MANS', \n",
    "               'LILLE', \n",
    "               'LYON PART DIEU', \n",
    "               'MACON LOCHE', \n",
    "               'MADRID', \n",
    "               'MARNE LA VALLEE', \n",
    "               'MARSEILLE ST CHARLES', \n",
    "               'METZ', \n",
    "               'MONTPELLIER', \n",
    "               'MULHOUSE VILLE', \n",
    "               'NANCY', \n",
    "               'NANTES', \n",
    "               'NICE VILLE', \n",
    "               'NIMES', \n",
    "               'PARIS EST', \n",
    "               'PARIS LYON', \n",
    "               'PARIS MONTPARNASSE', \n",
    "               'PARIS NORD', \n",
    "               'PARIS VAUGIRARD', \n",
    "               'PERPIGNAN', \n",
    "               'POTIIERS', \n",
    "               'QUIMPER', \n",
    "               'REIMS', \n",
    "               'RENNES', \n",
    "               'SAINT ETIENNE CHATEAUCREUX', \n",
    "               'ST MALO', \n",
    "               'ST PIERRE DES CORPS', \n",
    "               'STRASBOURG', \n",
    "               'STUTTGART', \n",
    "               'TOULON', \n",
    "               'TOULOUSE MATABIAU', \n",
    "               'TOURCOING', \n",
    "               'TOURS', \n",
    "               'VALENCE ALIXAN TGV', \n",
    "               'VANNES', \n",
    "               'ZURICH']\n",
    "\n",
    "max_val = 0\n",
    "max_city = \"\"\n",
    "\n",
    "for x in range(len(csv[\"Departure station\"])):\n",
    "    for cities in cities_list:\n",
    "        if (x in csv[\"Departure station\"]):\n",
    "            a = lev.ratio(csv[\"Departure station\"][x], cities)\n",
    "            if (a > max_val):\n",
    "                max_val = a\n",
    "                max_city = cities\n",
    "    max_val = 0\n",
    "    csv[\"Departure station\"][x] = max_city\n",
    "    max_city = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Arrival station\n",
    "We convert the column to strings <br>\n",
    "We remove any station name that contains numbers <br>\n",
    "Using levenshtein's algorithm, we find the closest station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv[\"Arrival station\"] = csv[\"Arrival station\"].convert_dtypes(str)\n",
    "mask = csv[\"Arrival station\"].str.contains(r\".*\\d.*\", na=False)\n",
    "csv.loc[mask, \"Arrival station\"] = np.nan\n",
    "csv[\"Departure station\"] = csv[\"Departure station\"].str.upper()\n",
    "\n",
    "max_val = 0\n",
    "max_city = \"\"\n",
    "\n",
    "for x in range(len(csv[\"Arrival station\"])):\n",
    "    for cities in cities_list:\n",
    "        if (x in csv[\"Arrival station\"]):\n",
    "            a = lev.ratio(csv[\"Arrival station\"][x], cities)\n",
    "            if (a > max_val):\n",
    "                max_val = a\n",
    "                max_city = cities\n",
    "    max_val = 0\n",
    "    csv[\"Arrival station\"][x] = max_city\n",
    "    max_city = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Average journey time\n",
    "We remove any data that contains letters <br>\n",
    "We convert the column to floats <br>\n",
    "We remove any journey time lower than 0 minutes (no time travellers here) <br>\n",
    "We remove any journey time higher than 1500 minutes (no journey takes 25 hours right?) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Average journey time\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Average journey time\"] = np.nan\n",
    "csv[\"Average journey time\"] = csv[\"Average journey time\"].convert_dtypes(float)\n",
    "csv.loc[csv[\"Average journey time\"] < 0, \"Average journey time\"] = np.nan\n",
    "csv.loc[csv[\"Average journey time\"] > 1500, \"Average journey time\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Number of scheduled trains\n",
    "We remove any data that contains letters <br>\n",
    "We remove any float since an amount of trains can't be a float <br>\n",
    "We remove any negative value (we don't want ghost trains) <br>\n",
    "We convert the column to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Number of scheduled trains\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Number of scheduled trains\"] = np.nan\n",
    "csv.loc[csv[\"Number of scheduled trains\"] % 1 != 0, \"Number of scheduled trains\"] = np.nan\n",
    "csv.loc[csv[\"Number of scheduled trains\"] < 0, \"Number of scheduled trains\"] = np.nan\n",
    "csv[\"Number of scheduled trains\"] = csv[\"Number of scheduled trains\"].convert_dtypes(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Number of cancelled trains\n",
    "We remove any data that contains letters <br>\n",
    "We remove any float since an amount of trains can't be a float <br>\n",
    "We remove any negative value (we don't want ghost trains) <br>\n",
    "We convert the column to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Number of cancelled trains\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Number of cancelled trains\"] = np.nan\n",
    "csv.loc[csv[\"Number of cancelled trains\"] % 1 != 0, \"Number of cancelled trains\"] = np.nan\n",
    "csv.loc[csv[\"Number of scheduled trains\"] < 0, \"Number of scheduled trains\"] = np.nan\n",
    "csv[\"Number of cancelled trains\"] = csv[\"Number of cancelled trains\"].convert_dtypes(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Number of trains delayed at departure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Number of trains delayed at departure\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Number of trains delayed at departure\"] = np.nan\n",
    "csv.loc[csv[\"Number of trains delayed at departure\"] % 1 != 0, \"Number of trains delayed at departure\"] = np.nan\n",
    "csv.loc[csv[\"Number of trains delayed at departure\"] > csv[\"Number of scheduled trains\"], \"Number of trains delayed at departure\"] = np.nan\n",
    "csv[\"Number of trains delayed at departure\"] = csv[\"Number of trains delayed at departure\"].convert_dtypes(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Average delay of late trains at departure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Average delay of late trains at departure\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Average delay of late trains at departure\"] = np.nan\n",
    "csv[\"Average delay of late trains at departure\"] = csv[\"Average delay of late trains at departure\"].convert_dtypes(float)\n",
    "csv.loc[csv[\"Average delay of late trains at departure\"] < 0, \"Average delay of late trains at departure\"] = np.nan\n",
    "csv.loc[csv[\"Average delay of late trains at departure\"] == 118.28872062060988, \"Average delay of late trains at departure\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Average delay of all trains at departure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Average delay of all trains at departure\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Average delay of all trains at departure\"] = np.nan\n",
    "csv[\"Average delay of all trains at departure\"] = csv[\"Average delay of all trains at departure\"].convert_dtypes(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Number of trains delayed at arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Number of trains delayed at arrival\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Number of trains delayed at arrival\"] = np.nan\n",
    "csv.loc[csv[\"Number of trains delayed at arrival\"] % 1 != 0, \"Number of trains delayed at arrival\"] = np.nan\n",
    "csv.loc[csv[\"Number of trains delayed at arrival\"] > csv[\"Number of scheduled trains\"], \"Number of trains delayed at arrival\"] = np.nan\n",
    "csv[\"Number of trains delayed at arrival\"] = csv[\"Number of trains delayed at arrival\"].convert_dtypes(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Average delay of late trains at arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Average delay of late trains at arrival\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Average delay of late trains at arrival\"] = np.nan\n",
    "csv[\"Average delay of late trains at arrival\"] = csv[\"Average delay of late trains at arrival\"].convert_dtypes(float)\n",
    "csv.loc[csv[\"Average delay of late trains at arrival\"] < 0, \"Average delay of late trains at arrival\"] = np.nan\n",
    "csv.loc[csv[\"Average delay of late trains at arrival\"] > 330, \"Average delay of late trains at arrival\"] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Average delay of all trains at arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Average delay of all trains at arrival\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Average delay of all trains at arrival\"] = np.nan\n",
    "csv[\"Average delay of all trains at arrival\"] = csv[\"Average delay of all trains at arrival\"].convert_dtypes(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Number of trains delayed > 15 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Number of trains delayed > 15min\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Number of trains delayed > 15min\"] = np.nan\n",
    "csv.loc[csv[\"Number of trains delayed > 15min\"] % 1 != 0, \"Number of trains delayed > 15min\"] = np.nan\n",
    "csv.loc[csv[\"Number of trains delayed > 15min\"] > csv[\"Number of trains delayed at departure\"] + csv[\"Number of trains delayed at arrival\"], \"Number of trains delayed > 15min\"] = np.nan\n",
    "csv[\"Number of trains delayed > 15min\"] = csv[\"Number of trains delayed > 15min\"].convert_dtypes(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Average delay of trains > 15min (if competing with flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Average delay of trains > 15min (if competing with flights)\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Average delay of trains > 15min (if competing with flights)\"] = np.nan\n",
    "csv[\"Average delay of trains > 15min (if competing with flights)\"] = csv[\"Average delay of trains > 15min (if competing with flights)\"].convert_dtypes(float)\n",
    "csv.loc[csv[\"Average delay of trains > 15min (if competing with flights)\"] > 330, \"Average delay of trains > 15min (if competing with flights)\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Number of trains delayed > 30min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Number of trains delayed > 30min\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Number of trains delayed > 30min\"] = np.nan\n",
    "csv.loc[csv[\"Number of trains delayed > 30min\"] % 1 != 0, \"Number of trains delayed > 30min\"] = np.nan\n",
    "csv.loc[csv[\"Number of trains delayed > 30min\"] > csv[\"Number of trains delayed > 15min\"], \"Number of trains delayed > 30min\"] = np.nan\n",
    "csv[\"Number of trains delayed > 30min\"] = csv[\"Number of trains delayed > 30min\"].convert_dtypes(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Number of trains delayed > 60min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Number of trains delayed > 60min\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Number of trains delayed > 60min\"] = np.nan\n",
    "csv.loc[csv[\"Number of trains delayed > 60min\"] % 1 != 0, \"Number of trains delayed > 60min\"] = np.nan\n",
    "csv.loc[csv[\"Number of trains delayed > 60min\"] > csv[\"Number of trains delayed > 30min\"], \"Number of trains delayed > 60min\"] = np.nan\n",
    "csv[\"Number of trains delayed > 60min\"] = csv[\"Number of trains delayed > 60min\"].convert_dtypes(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Pct delay due to external causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Pct delay due to external causes\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Pct delay due to external causes\"] = np.nan\n",
    "csv[\"Pct delay due to external causes\"] = csv[\"Pct delay due to external causes\"].convert_dtypes(float)\n",
    "csv.loc[(csv[\"Pct delay due to external causes\"] > 100) | (csv[\"Pct delay due to external causes\"] < 0), \"Pct delay due to external causes\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Pct delay due to infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Pct delay due to infrastructure\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Pct delay due to infrastructure\"] = np.nan\n",
    "csv[\"Pct delay due to infrastructure\"] = csv[\"Pct delay due to infrastructure\"].convert_dtypes(float)\n",
    "csv.loc[(csv[\"Pct delay due to infrastructure\"] > 100) | (csv[\"Pct delay due to infrastructure\"] < 0), \"Pct delay due to infrastructure\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Pct delay due to traffic management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Pct delay due to traffic management\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Pct delay due to traffic management\"] = np.nan\n",
    "csv[\"Pct delay due to traffic management\"] = csv[\"Pct delay due to traffic management\"].convert_dtypes(float)\n",
    "csv.loc[(csv[\"Pct delay due to traffic management\"] > 99) | (csv[\"Pct delay due to traffic management\"] < 0), \"Pct delay due to traffic management\"] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Pct delay due to rolling stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Pct delay due to rolling stock\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Pct delay due to rolling stock\"] = np.nan\n",
    "csv[\"Pct delay due to rolling stock\"] = csv[\"Pct delay due to rolling stock\"].convert_dtypes(float)\n",
    "csv.loc[(csv[\"Pct delay due to rolling stock\"] > 99) | (csv[\"Pct delay due to rolling stock\"] < 0), \"Pct delay due to rolling stock\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Pct delay due to station management and equipment reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Pct delay due to station management and equipment reuse\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Pct delay due to station management and equipment reuse\"] = np.nan\n",
    "csv[\"Pct delay due to station management and equipment reuse\"] = csv[\"Pct delay due to station management and equipment reuse\"].convert_dtypes(float)\n",
    "csv.loc[(csv[\"Pct delay due to station management and equipment reuse\"] > 100) | (csv[\"Pct delay due to station management and equipment reuse\"] < 0), \"Pct delay due to station management and equipment reuse\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Pct delay due to passenger handling (crowding, disabled persons, connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_with_letters = csv[\"Pct delay due to passenger handling (crowding, disabled persons, connections)\"].astype(str).str.contains(r\"[a-zA-Z]\", na=False)\n",
    "csv.loc[numbers_with_letters, \"Pct delay due to passenger handling (crowding, disabled persons, connections)\"] = np.nan\n",
    "csv[\"Pct delay due to passenger handling (crowding, disabled persons, connections)\"] = csv[\"Pct delay due to passenger handling (crowding, disabled persons, connections)\"].convert_dtypes(float)\n",
    "csv.loc[(csv[\"Pct delay due to passenger handling (crowding, disabled persons, connections)\"] > 100) | (csv[\"Pct delay due to passenger handling (crowding, disabled persons, connections)\"] < 0), \"Pct delay due to passenger handling (crowding, disabled persons, connections)\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final informations <br>\n",
    "Out of 10659 final lines, 956 are perfect (no empty column), about 8.97% <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines: 10659 \n",
      "Perfect lines: 956 \n",
      "~8.97%\n"
     ]
    }
   ],
   "source": [
    "csv = csv.drop_duplicates()\n",
    "csv_dropped = csv.dropna()\n",
    "\n",
    "count = len(csv)\n",
    "perfect_count = len(csv_dropped)\n",
    "\n",
    "# print(f\"Total lines: {count}\", f\"\\nPerfect lines: {perfect_count}\", f\"\\n~{round(perfect_count / count * 100, 2)}%\")\n",
    "csv = csv.sort_values([\"Date\", \"Service\", \"Departure station\", \"Arrival station\"])\n",
    "csv.to_csv(\"cleaned_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
